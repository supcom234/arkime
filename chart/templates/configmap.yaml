{{- $elastic_secret := (lookup "v1" "Secret" "dataplane-ek" .Values.elastic_pass).data }}
{{- $elastic_password := get $elastic_secret .Values.elastic_user | b64dec }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-configini
  namespace: arkime
  annotations:
    "helm.sh/hook": "pre-install"
    "helm.sh/hook-weight": "-10"
    "helm.sh/hook-delete-policy": "before-hook-creation"
data:
  config.ini: |
    # Latest settings documentation: https://arkime.com/settings
    #
    # Arkime capture/viewer uses a tiered system for configuration variables. This allows Arkime
    # to share one config file for many machines. The ordering of sections in this
    # file doesn't matter.
    #
    # Order of config variables use:
    # 1st) [optional] The section titled with the node name is used first.
    # 2nd) [optional] If a node has a nodeClass variable, the section titled with
    #      the nodeClass name is used next. Sessions will be tagged with
    #      class:<node class name> which may be useful if watching different networks.
    # 3rd) The section titled "default" is used last.

    [default]

    # Comma seperated list of OpenSearch/Elasticsearch host:port combinations. If not using a
    # Elasticsearch load balancer, a different OpenSearch/Elasticsearch node in the cluster can be 
    # specified for each Arkime node to help spread load on high volume clusters. For user/password
    # use https://user:pass@host:port OR elasticsearchBasicAuth
    elasticsearch={{ .Values.elastic_protocol }}://{{ .Values.elastic_user }}:{{ $elastic_password }}@{{ .Values.elastic_host }}:{{ .Values.elastic_port }}
    
    # Cert file to use, comment out to use http instead
    # certFile=/etc/ssl/certs/moloch.crt
    # Private key file to use, comment out to use http instead
    # keyFile=/etc/ssl/certs/moloch.key

    # File with trusted roots/certs. WARNING! this replaces default roots
    # Useful with self signed certs and can be set per node.
    caTrustFile=/usr/local/share/ca-certificates/elastic_ca.crt
    
    # How often to create a new ElasticSearch index. hourly,hourly[23468],hourly12,daily,weekly,monthly
    rotateIndex=hourly6

    # Password Hash Secret - Must be in default section. Since OpenSearch/Elasticsearch
    # is wide open by default, we encrypt the stored password hashes with this
    # so a malicous person can't insert a working new account.
    # Comment out for no user authentication.
    # Changing the value will make all previously stored passwords no longer work.
    # Make this RANDOM, you never need to type in
    passwordSecret=default-password
    
    # HTTP Digest Realm - Must be in default section. Changing the value
    # will make all previously stored passwords no longer work
    httpRealm=Arkime
    
    # The directory to save raw pcap files to
    pcapDir=/opt/arkime/raw

    # TCP timeout value. Arkime writes a session record after this many seconds
    # of inactivity.
    tcpTimeout=10

    # Arkime writes a session record after this many seconds, no matter if
    # active or inactive
    tcpSaveTimeout=10

    # UDP timeout value. Arkime assumes the UDP session is ended after this
    # many seconds of inactivity.
    udpTimeout=30

    # ICMP timeout value. Arkime assumes the ICMP session is ended after this
    # many seconds of inactivity.
    icmpTimeout=10
    
    # Semicolon ';' seperated list of interfaces to listen on for traffic
    interface={{ .Values.capture_interface }}

    # Approximate max number of active sessions Arkime will try and monitor
    maxStreams=14000000

    # Arkime writes a session record after this many packets
    maxPackets=10000

    # The port to listen on, by default 8005
    viewPort={{ .Values.listen_port }}

    # The host/ip to listen on, by default 0.0.0.0 which is ALL
    viewHost=0.0.0.0

    # A MaxMind account is now required, Arkime checks several install locations, or
    # will work without Geo files installed. See https://arkime.com/faq#maxmind
    geoLite2Country=/opt/arkime/etc/GeoLite2-Country.mmdb
    geoLite2ASN=/opt/arkime/etc/GeoLite2-ASN.mmdb
    
    # Path of the rir assignments file
    #  https://www.iana.org/assignments/ipv4-address-space/ipv4-address-space.csv
    rirFile=/opt/arkime/etc/ipv4-address-space.csv

    # Path of the OUI file from wireshark
    #  https://raw.githubusercontent.com/wireshark/wireshark/master/manuf
    ouiFile=/opt/arkime/etc/oui.txt

    # Arkime rules to allow you specify actions to perform when criteria are met with certain fields or state. 
    # See https://arkime.com/rulesformat
    rulesFiles=/opt/arkime/rules.txt

    # User to drop privileges to. The pcapDir must be writable by this user or group below
    #dropUser=nobody

    # Group to drop privileges to. The pcapDir must be writable by this group or user above
    #dropGroup=daemon

    # Header to use for determining the username to check in the database for instead of
    # using http digest. Use this if apache or something else is doing the auth.
    # Set viewHost to localhost or use iptables
    # Might need something like this in the httpd.conf
    # RewriteRule .* - [E=ENV_RU:%{REMOTE_USER}]
    # RequestHeader set ARKIME_USER %{ENV_RU}e
    userNameHeader=anonymous

    #
    # Headers to use to determine if user from `userNameHeader` is
    # authorized to use the system, and if so create a new user
    # in the Arkime user database. This implementation expects that
    # the users LDAP/AD groups (or similar) are populated into an
    # HTTP header by the Apache (or similar) referenced above.
    # The JSON in userAutoCreateTmpl is used to insert the new
    # user into the arkime database (if not already present)
    # and additional HTTP headers can be sourced from the request
    # to populate various fields.
    #
    # The example below pulls verifies that an HTTP header called `roles`
    # is present, and contains the value "arkime-user". If this authorization
    # check passes, the user database is inspected for the user in `userNameHeader`
    # and if it is not present it is created. The system uses the `uid` header from the
    # request and uses them to populate `userId` and `userName`
    # fields for the new user record.
    #
    # Once the user record is created, this functionaity
    # neither updates nor deletes the data, though if the user is no longer
    # reported to be in the group, access is denied regardless of the status
    # in the arkime database.
    #
    # requiredAuthHeader=roles
    # requiredAuthHeaderVal=arkime-user
    
    # For OIDC
    # authDiscoverURL=[DISCOVER or ISSUER or WELLKNOWN URL]
    # authClientId=[CLIENTID]
    # authClientSecret=[CLIENTSECRET]
    # authUserIdField=preferred_username
    # authRedirectURIs=http://ARKIMEHOST:PORT/auth/login/callback
    # Optional to auto create users
    # userAutoCreateTmpl={"userId": "${this.preferred_username}", "userName": "${this.name}", "enabled": true, "webEnabled": true, "headerAuthEnabled": true, "emailSearch": true, "createEnabled": false, "removeEnabled": false, "packetSearch": true }

    # Should we parse extra smtp traffic info
    parseSMTP=true
    
    # Should we parse extra smb traffic info
    parseSMB=true

    # Should we parse HTTP QS Values
    parseQSValue=true

    # Should we calculate sha256 for bodies
    supportSha256=false

    # Only index HTTP request bodies less than this number of bytes */
    maxReqBody=64

    # Only store request bodies that Utf-8?
    config.reqBodyOnlyUtf8=true

    # Semicolon ';' seperated list of SMTP Headers that have ips, need to have the terminating colon ':'
    smtpIpHeaders=X-Originating-IP:;X-Barracuda-Apparent-Source-IP:

    # Semicolon ';' seperated list of directories to load parsers from
    parsersDir=/opt/arkime/parsers

    # Semicolon ';' seperated list of directories to load plugins from
    pluginsDir=/opt/arkime/plugins    

    # Semicolon ';' seperated list of plugins to load and the order to load in
    # plugins=tagger.so; netflow.so
    plugins=suricata.so
    suricataAlertFile=/opt/suricata/logs/eve-alerts.json

    # Plugins to load as root, usually just readers
    #rootPlugins=reader-pfring; reader-daq.so

    # Semicolon ';' seperated list of viewer plugins to load and the order to load in
    # viewerPlugins=wise.js

    # NetFlowPlugin
    # Input device id, 0 by default
    #netflowSNMPInput=1
    # Outout device id, 0 by default
    #netflowSNMPOutput=2
    # Netflow version 1,5,7 supported, 7 by default
    #netflowVersion=1
    # Semicolon ';' seperated list of netflow destinations
    #netflowDestinations=localhost:9993

    # Specify the max number of indices we calculate spidata for.
    # ES will blow up if we allow the spiData to search too many indices.
    #spiDataMaxIndices=4

    # Uncomment the following to allow direct uploads. This is experimental
    #uploadCommand=ARKIME_INSTALL_DIR/bin/capture --copy -n {NODE} -r {TMPFILE} -c {CONFIG} {TAGS}

    # Title Template
    # _cluster_ = ES cluster name
    # _userId_  = logged in User Id
    # _userName_ = logged in User Name
    # _page_ = internal page name
    # _expression_ = current search expression if set, otherwise blank
    # _-expression_ = " - " + current search expression if set, otherwise blank, prior spaces removed
    # _view_ = current view if set, otherwise blank
    # _-view_ = " - " + current view if set, otherwise blank, prior spaces removed
    #titleTemplate=_cluster_ - _page_ _-view_ _-expression_

    # Number of threads processing packets
    # Start with 5 packet threads, increase by 1 if getting thread drops.  Should be about 1.5 x # Gbps that need to be captured
    packetThreads=5

    # ADVANCED - Semicolon ';' seperated list of files to load for config. Files are loaded
    # in order and can replace values set in this file or previous files.
    #includes=

    # ADVANCED - How is pcap written to disk
    #  simple          = use O_DIRECT if available, writes in pcapWriteSize chunks,
    #                    a file per packet thread.
    #  simple-nodirect = don't use O_DIRECT. Required for zfs and others
    #pcapWriteMethod=simple

    # ADVANCED - Buffer size when writing pcap files. Should be a multiple of the raid 5 or xfs
    # stripe size. Defaults to 256k
    #pcapWriteSize=262143

    # ADVANCED - Number of bytes to bulk index at a time
    #dbBulkSize=300000

    #Compress requests to ES, MUST have "http.compression: true" in elasticsearch.yml file
    #compressES=false

    # ADVANCED - Max number of connections to OpenSearch/Elasticsearch
    maxESConns={{ .Values.maxESConns }}

    # ADVANCED - Max number of es requests outstanding in q
    maxESRequests={{ .Values.maxESRequests }}

    # ADVANCED - Number of packets to ask libpcap to read per poll/spin
    # Increasing may hurt stats and ES performance
    # Decreasing may cause more dropped packets
    packetsPerPoll={{ .Values.packetsPerPoll }}

    # ADVANCED - The base path for Arkime web access. Must end with a / or bad things will happen
    # Only set when using a reverse proxy
    # webBasePath=/arkime/

    # Not present anymore
    #antiSynDrop=false

    # DEBUG - Write to stdout info every X packets.
    # Set to -1 to never log status
    logEveryXPackets=100000

    # DEBUG - Write to stdout unknown protocols
    logUnknownProtocols=false

    # DEBUG - Write to stdout OpenSearch/Elasticsearch requests
    logESRequests=true

    # DEBUG - Write to stdout file creation information
    logFileCreation=true

    ### High Performance settings
    magicMode=basic
    pcapReadMethod=tpacketv3

    # Increase by 1 if still getting Input Drops
    # tpacketv3NumThreads=1

    # Default caused failure during testing
    # tpacketv3BlockSize=65536

    # Set to number of packets a second, if still overflowing try 400k
    maxPacketsInQueue={{ .Values.maxPacketsInQueue }}
